{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e98ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/tparshakova/Documents/GPT-opt/venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gptopt.optim.attn_utils import *\n",
    "from gptopt.optim.fast_pdhg import *\n",
    "from gptopt.optim.least_squares import *\n",
    "from gptopt.optim.linop import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a1cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from gptopt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85252805",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxit = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf0ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmin import TorchLinearOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf8189",
   "metadata": {},
   "source": [
    "# Vectorization of $\\mathcal{A}Z = Z_1^TA_1 + A_2^TZ_2$\n",
    "$$\n",
    "K = [(A_1^\\top \\otimes I_n)P, I_n \\otimes A_2^\\top],\n",
    "\\qquad \n",
    "K^\\top = \\begin{bmatrix}\n",
    "P^\\top(A_1 \\otimes I_n) \\\\\n",
    "I_n \\otimes A_2\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "where $P$ is a permutation matrix s.t $P\\text{vec}(Z^\\top) = \\text{vec}(Z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b443d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "for (m, n) in [(30, 60), (60, 30), (60, 60)]:\n",
    "    # print(f\"{m}x{n}\")\n",
    "    for _ in range(5): \n",
    "        A1 = torch.randn((m, n), device=device)\n",
    "        A2 = torch.randn((m, n), device=device)\n",
    "        Z = torch.randn((2 * m, n), device=A2.device, dtype=A2.dtype)\n",
    "        Z1, Z2 = Z[:m, :], Z[m:, :]\n",
    "\n",
    "        A_linop = attn_linop_from_matrices(A1, A2)\n",
    "\n",
    "        K = matcal_A_to_kron_Kron(A1, A2) \n",
    "        Kz = K @ torch.cat([Z1.reshape(-1), Z2.T.reshape(-1)], dim=0)\n",
    "        vecAZ = mathcal_A_linop(A1=A1, A2=A2, Z=Z).T.reshape(-1)\n",
    "        vecAZ2 = A_linop.matvec(Z).T.reshape(-1)\n",
    "        assert torch.allclose(Kz, vecAZ2, atol=1e-5)\n",
    "        assert torch.allclose(Kz, vecAZ, atol=1e-5), print(torch.max(torch.abs(Kz - vecAZ)).item())\n",
    "\n",
    "        Y = torch.randn((n, n), device=A2.device, dtype=A2.dtype)\n",
    "        KTy = K.T @ Y.T.reshape(-1)\n",
    "        AadjY = mathcal_A_adj_linop(A1=A1, A2=A2, Y=Y)\n",
    "        AadjY2 = A_linop.rmatvec(Y)\n",
    "        vecAadjY2 = torch.cat([AadjY2[:m].reshape(-1), AadjY2[m:].T.reshape(-1)], dim=0)\n",
    "        vecAadjY = torch.cat([AadjY[:m].reshape(-1), AadjY[m:].T.reshape(-1)], dim=0)\n",
    "        assert torch.allclose(KTy, vecAadjY2, atol=1e-5)\n",
    "        assert torch.allclose(KTy, vecAadjY, atol=1e-5), print(torch.max(torch.abs(KTy - vecAadjY)).item())\n",
    "\n",
    "        Az = A_linop.matvec(Z)\n",
    "        Aty = A_linop.rmatvec(Y) \n",
    "        tr1 = (Az * Y).sum()\n",
    "        tr2 = (Z * Aty).sum()\n",
    "        assert torch.allclose(tr1, tr2)\n",
    "\n",
    "print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca1a53",
   "metadata": {},
   "source": [
    "# Ruiz equilibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71128195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30x60\n",
      "maxcol=3.9262e-02, maxrow=3.9262e-02\n",
      "maxcol 1.7660601139068604 maxrow 1.7660601139068604\n",
      "maxcol=3.9224e-02, maxrow=3.9224e-02\n",
      "maxcol 1.7172335386276245 maxrow 1.7172335386276245\n",
      "maxcol=4.4791e-02, maxrow=4.4791e-02\n",
      "maxcol 1.9314849376678467 maxrow 1.9314849376678467\n",
      "maxcol=3.6551e-02, maxrow=3.6551e-02\n",
      "maxcol 1.7974989414215088 maxrow 1.7974989414215088\n",
      "maxcol=3.5328e-02, maxrow=3.5328e-02\n",
      "maxcol 1.6759533882141113 maxrow 1.6759533882141113\n",
      "60x30\n",
      "maxcol=3.4277e-02, maxrow=3.4277e-02\n",
      "maxcol 2.0323734283447266 maxrow 2.0323734283447266\n",
      "maxcol=4.2954e-02, maxrow=4.2954e-02\n",
      "maxcol 2.184307813644409 maxrow 2.184307813644409\n",
      "maxcol=3.4019e-02, maxrow=3.4019e-02\n",
      "maxcol 1.8383127450942993 maxrow 1.8383127450942993\n",
      "maxcol=3.7454e-02, maxrow=3.7454e-02\n",
      "maxcol 1.9406521320343018 maxrow 1.9406521320343018\n",
      "maxcol=4.1577e-02, maxrow=4.1577e-02\n",
      "maxcol 2.243189573287964 maxrow 2.243189573287964\n",
      "60x60\n",
      "maxcol=3.7261e-02, maxrow=3.7261e-02\n",
      "maxcol 1.78279709815979 maxrow 1.78279709815979\n",
      "maxcol=3.6056e-02, maxrow=3.6056e-02\n",
      "maxcol 1.7595891952514648 maxrow 1.7595891952514648\n",
      "maxcol=3.7662e-02, maxrow=3.7662e-02\n",
      "maxcol 1.763007640838623 maxrow 1.763007640838623\n",
      "maxcol=4.2020e-02, maxrow=4.2020e-02\n",
      "maxcol 1.6417945623397827 maxrow 1.6417945623397827\n",
      "maxcol=3.9993e-02, maxrow=3.9993e-02\n",
      "maxcol 1.7447491884231567 maxrow 1.7447491884231567\n"
     ]
    }
   ],
   "source": [
    "for (m, n) in [(30, 60), (60, 30), (60, 60)]:\n",
    "    print(f\"{m}x{n}\")\n",
    "    for _ in range(5): \n",
    "        std2 = 0.1\n",
    "        std1 = 0.01\n",
    "        rank_ratio = 1\n",
    "        A2, A1, G1, G2, A2_np, A1_np, G1_np, G2_np, lamb_max = gaussian_data(m, n, std1=std1, std2=std2, \n",
    "                                                                 rank_ratio=rank_ratio, G_in_range=True)\n",
    "\n",
    "        K = matcal_A_to_kron_Kron(A1, A2)\n",
    "        print(f\"maxcol={K.abs().max(dim=0).values.max().item():.4e}, maxrow={K.abs().max(dim=1).values.max().item():.4e}\")\n",
    "        R, Gamma1, Gamma2= ruiz_equilibration(A1=A1, A2=A2, num_iters=10)\n",
    "        tildeK = R.T.reshape(-1)[:, None] * K\n",
    "        tildeK[:, :m*n] *= Gamma1.T.reshape(-1)[None, :]\n",
    "        tildeK[:, m*n:] *= Gamma2.T.reshape(-1)[None, :]\n",
    "\n",
    "        print(\"maxcol\", tildeK.abs().max(dim=0).values.max().item(),\n",
    "            \"maxrow\", tildeK.abs().max(dim=1).values.max().item())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff86d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2516e6ab",
   "metadata": {},
   "source": [
    "# Basic tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3059873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxpy_prox_l1(x0, rho, R=None):\n",
    "    x = cp.Variable(x0.shape)\n",
    "    obj = rho * cp.sum(cp.abs(x)) \n",
    "    if R is not None:\n",
    "        W = 1 / R**0.5\n",
    "        obj += (1/2) * cp.sum_squares(cp.multiply(W, x - x0))\n",
    "    else:\n",
    "        obj += (1/2) * cp.sum_squares(x - x0)\n",
    "    objective = cp.Minimize(obj)\n",
    "    prob = cp.Problem(objective, [])\n",
    "    prob.solve(solver=cp.CLARABEL, max_iter=10000, tol_gap_abs=1e-12, tol_gap_rel=1e-12)\n",
    "    assert prob.status in [\"optimal\"], print(prob.status)\n",
    "    return x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d94354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    n  = torch.randint(25, 80, ()).item()\n",
    "    m  = torch.randint(25, 80, ()).item()\n",
    "    R = torch.rand(m, n, dtype=torch.float64) + 0.1\n",
    "    X0 = torch.randn(m, n, dtype=torch.float64) * 100\n",
    "    rho = torch.rand(1).item() * 0.5 + 0.1\n",
    "    X1 = prox_l1(X0, rho, R=R).cpu().numpy()\n",
    "    X2 = cvxpy_prox_l1(X0.cpu().numpy(), rho, R=R.cpu().numpy()) \n",
    "    assert np.allclose(X1, X2, rtol=1e-4, atol=1e-4), \"prox_l1 mismatch!\"\n",
    "print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26587ddc",
   "metadata": {},
   "source": [
    "## Diagonal scaling for linear operator to shrink operator number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628f3c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal PDHG scaling computed.\n",
      "1.0766e-01 +- 2.0185e-02, 1.5832e-01 +- 1.9312e-02, 1.6263e-01 +- 6.0898e-02\n",
      "A.shape=torch.Size([8, 9]), rank_tol=8.0000e+00, sigma_max=4.8292e+00, fro_norm=7.9894e+00\n",
      "A.shape=torch.Size([5, 9]), rank_tol=5.0000e+00, sigma_max=4.0618e+00, fro_norm=6.1722e+00\n",
      "[00] n=9 p1=5 p2=8  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.704098  (impl=0.704098)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "8.6957e-02 +- 2.0812e-02, 1.7292e-01 +- 4.5533e-02, 1.6880e-01 +- 7.4941e-02\n",
      "A.shape=torch.Size([8, 8]), rank_tol=8.0000e+00, sigma_max=5.1265e+00, fro_norm=8.4192e+00\n",
      "A.shape=torch.Size([7, 8]), rank_tol=7.0000e+00, sigma_max=4.2295e+00, fro_norm=7.1814e+00\n",
      "[01] n=8 p1=7 p2=8  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.664996  (impl=0.664996)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.5254e-01 +- 3.8808e-02, 1.5136e-01 +- 2.4287e-02, 1.4593e-01 +- 4.1929e-02\n",
      "A.shape=torch.Size([4, 8]), rank_tol=4.0000e+00, sigma_max=4.5893e+00, fro_norm=6.5231e+00\n",
      "A.shape=torch.Size([4, 8]), rank_tol=4.0000e+00, sigma_max=4.7248e+00, fro_norm=5.7300e+00\n",
      "[02] n=8 p1=4 p2=4  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.798542  (impl=0.798542)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "7.8359e-02 +- 8.1918e-03, 2.3359e-01 +- 5.9619e-02, 3.7066e-01 +- 1.8834e-01\n",
      "A.shape=torch.Size([7, 4]), rank_tol=4.0000e+00, sigma_max=4.1958e+00, fro_norm=6.2127e+00\n",
      "A.shape=torch.Size([6, 4]), rank_tol=4.0000e+00, sigma_max=4.4221e+00, fro_norm=5.9437e+00\n",
      "[03] n=4 p1=6 p2=7  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.716247  (impl=0.716247)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.4538e-01 +- 1.8557e-02, 3.6370e-01 +- 1.1410e-01, 3.2244e-01 +- 8.4898e-02\n",
      "A.shape=torch.Size([2, 4]), rank_tol=2.0000e+00, sigma_max=2.3388e+00, fro_norm=2.7719e+00\n",
      "A.shape=torch.Size([7, 4]), rank_tol=4.0000e+00, sigma_max=3.5415e+00, fro_norm=4.8746e+00\n",
      "[04] n=4 p1=7 p2=2  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.770892  (impl=0.770892)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "9.8538e-02 +- 1.8844e-02, 2.4469e-01 +- 7.5838e-02, 1.5440e-01 +- 3.2028e-02\n",
      "A.shape=torch.Size([9, 7]), rank_tol=7.0000e+00, sigma_max=5.7364e+00, fro_norm=9.2136e+00\n",
      "A.shape=torch.Size([3, 7]), rank_tol=3.0000e+00, sigma_max=2.7845e+00, fro_norm=3.3829e+00\n",
      "[05] n=7 p1=3 p2=9  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.709404  (impl=0.709404)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.6584e-01 +- 4.7218e-02, 1.4204e-01 +- 3.0117e-02, 1.3898e-01 +- 2.2995e-02\n",
      "A.shape=torch.Size([2, 9]), rank_tol=2.0000e+00, sigma_max=3.5535e+00, fro_norm=4.4831e+00\n",
      "A.shape=torch.Size([6, 9]), rank_tol=6.0000e+00, sigma_max=4.4267e+00, fro_norm=7.6288e+00\n",
      "[06] n=9 p1=6 p2=2  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.736571  (impl=0.736570)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.4760e-01 +- 3.7044e-02, 4.8698e-01 +- 2.2539e-01, 6.7842e-01 +- 2.2108e-01\n",
      "A.shape=torch.Size([3, 3]), rank_tol=3.0000e+00, sigma_max=1.6360e+00, fro_norm=1.8328e+00\n",
      "A.shape=torch.Size([7, 3]), rank_tol=3.0000e+00, sigma_max=3.7620e+00, fro_norm=4.5739e+00\n",
      "[07] n=3 p1=7 p2=3  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.865307  (impl=0.865307)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.1494e-01 +- 1.2542e-02, 1.8623e-01 +- 1.5956e-02, 1.5908e-01 +- 4.8804e-02\n",
      "A.shape=torch.Size([8, 8]), rank_tol=8.0000e+00, sigma_max=4.8121e+00, fro_norm=8.5243e+00\n",
      "A.shape=torch.Size([3, 8]), rank_tol=3.0000e+00, sigma_max=3.2150e+00, fro_norm=4.3855e+00\n",
      "[08] n=8 p1=3 p2=8  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.709671  (impl=0.709671)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.3296e-01 +- 3.7322e-02, 1.6264e-01 +- 9.1615e-02, 1.6876e-01 +- 4.5726e-02\n",
      "A.shape=torch.Size([8, 9]), rank_tol=8.0000e+00, sigma_max=5.1986e+00, fro_norm=8.0650e+00\n",
      "A.shape=torch.Size([3, 9]), rank_tol=3.0000e+00, sigma_max=3.7504e+00, fro_norm=5.3863e+00\n",
      "[09] n=9 p1=3 p2=8  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.712802  (impl=0.712802)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "2.4329e-01 +- 7.8554e-02, 2.0491e-01 +- 6.6022e-02, 2.1285e-01 +- 3.3640e-02\n",
      "A.shape=torch.Size([3, 8]), rank_tol=3.0000e+00, sigma_max=3.0525e+00, fro_norm=3.7723e+00\n",
      "A.shape=torch.Size([4, 8]), rank_tol=4.0000e+00, sigma_max=3.4438e+00, fro_norm=4.8281e+00\n",
      "[10] n=8 p1=4 p2=3  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.814294  (impl=0.814295)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "9.3269e-02 +- 9.2896e-03, 4.8677e-01 +- 2.9936e-01, 5.5683e-01 +- 5.2007e-01\n",
      "A.shape=torch.Size([7, 3]), rank_tol=3.0000e+00, sigma_max=3.8976e+00, fro_norm=5.2508e+00\n",
      "A.shape=torch.Size([5, 3]), rank_tol=3.0000e+00, sigma_max=3.5253e+00, fro_norm=3.9765e+00\n",
      "[11] n=3 p1=5 p2=7  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.822267  (impl=0.822267)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.4970e-01 +- 3.4940e-02, 1.2299e-01 +- 1.9946e-02, 1.9783e-01 +- 3.8475e-02\n",
      "A.shape=torch.Size([6, 8]), rank_tol=6.0000e+00, sigma_max=3.6450e+00, fro_norm=5.6067e+00\n",
      "A.shape=torch.Size([3, 8]), rank_tol=3.0000e+00, sigma_max=4.9961e+00, fro_norm=6.1061e+00\n",
      "[12] n=8 p1=3 p2=6  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.799876  (impl=0.799876)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "8.6032e-02 +- 1.8733e-02, 1.5482e-01 +- 5.2219e-02, 1.3694e-01 +- 4.5503e-02\n",
      "A.shape=torch.Size([6, 8]), rank_tol=6.0000e+00, sigma_max=5.6369e+00, fro_norm=8.7526e+00\n",
      "A.shape=torch.Size([7, 8]), rank_tol=7.0000e+00, sigma_max=5.2199e+00, fro_norm=8.0730e+00\n",
      "[13] n=8 p1=7 p2=6  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.708032  (impl=0.708033)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.9651e-01 +- 4.9107e-02, 2.1170e-01 +- 1.7429e-01, 1.0979e-01 +- 2.4152e-02\n",
      "A.shape=torch.Size([3, 9]), rank_tol=3.0000e+00, sigma_max=5.1336e+00, fro_norm=6.3844e+00\n",
      "A.shape=torch.Size([3, 9]), rank_tol=3.0000e+00, sigma_max=3.7527e+00, fro_norm=5.3612e+00\n",
      "[14] n=9 p1=3 p2=3  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.844362  (impl=0.844362)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.2373e-01 +- 2.5666e-02, 2.1262e-01 +- 6.5211e-02, 1.8979e-01 +- 1.3184e-02\n",
      "A.shape=torch.Size([4, 8]), rank_tol=4.0000e+00, sigma_max=3.3751e+00, fro_norm=4.6846e+00\n",
      "A.shape=torch.Size([9, 8]), rank_tol=8.0000e+00, sigma_max=4.3381e+00, fro_norm=6.9160e+00\n",
      "[15] n=8 p1=9 p2=4  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.694615  (impl=0.694616)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "3.6236e-01 +- 1.3943e-01, 1.6190e-01 +- 6.1340e-02, 1.4127e-01 +- 4.2652e-02\n",
      "A.shape=torch.Size([2, 9]), rank_tol=2.0000e+00, sigma_max=3.2347e+00, fro_norm=4.1746e+00\n",
      "A.shape=torch.Size([2, 9]), rank_tol=2.0000e+00, sigma_max=3.5541e+00, fro_norm=4.1265e+00\n",
      "[16] n=9 p1=2 p2=2  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.863461  (impl=0.863461)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.5434e-01 +- 2.4275e-02, 3.7356e-01 +- 1.3619e-01, 4.2781e-01 +- 2.6540e-01\n",
      "A.shape=torch.Size([3, 5]), rank_tol=3.0000e+00, sigma_max=2.5939e+00, fro_norm=2.9027e+00\n",
      "A.shape=torch.Size([8, 5]), rank_tol=5.0000e+00, sigma_max=3.3870e+00, fro_norm=4.8976e+00\n",
      "[17] n=5 p1=8 p2=3  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.807165  (impl=0.807165)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.3348e-01 +- 1.6111e-02, 3.1834e-01 +- 1.0164e-01, 3.9120e-01 +- 2.7475e-01\n",
      "A.shape=torch.Size([3, 5]), rank_tol=3.0000e+00, sigma_max=2.6358e+00, fro_norm=3.2444e+00\n",
      "A.shape=torch.Size([8, 5]), rank_tol=5.0000e+00, sigma_max=3.0015e+00, fro_norm=5.1389e+00\n",
      "[18] n=5 p1=8 p2=3  K_err=9.54e-07  ||R^1/2 K G^1/2||_2=0.706051  (impl=0.706051)  -> OK\n",
      "Diagonal PDHG scaling computed.\n",
      "1.2341e-01 +- 1.2741e-02, 1.8086e-01 +- 4.9977e-02, 1.7164e-01 +- 3.2407e-02\n",
      "A.shape=torch.Size([9, 8]), rank_tol=8.0000e+00, sigma_max=5.0148e+00, fro_norm=7.6426e+00\n",
      "A.shape=torch.Size([2, 8]), rank_tol=2.0000e+00, sigma_max=3.0799e+00, fro_norm=3.4032e+00\n",
      "[19] n=8 p1=2 p2=9  K_err=4.77e-07  ||R^1/2 K G^1/2||_2=0.775734  (impl=0.775734)  -> OK\n",
      "\n",
      "Summary: 20 / 20 passed (eta=0.99).\n"
     ]
    }
   ],
   "source": [
    "def A_op(Z1, Z2, A, B):\n",
    "    # Y = Z1^T B + A^T Z2\n",
    "    return Z1.T @ B + A.T @ Z2\n",
    "\n",
    "def A_adj(Y, A, B):\n",
    "    # (B Y^T, A Y)\n",
    "    return (B @ Y.T, A @ Y)\n",
    "\n",
    "def spec_norm_implicit(A, B, R, g1, g2, it=120):\n",
    "    # power iteration for preconditioned operator G^{1/2} A^* R A G^{1/2} \n",
    "    st = R.sqrt()        # (n,n)\n",
    "    ss1 = g1.sqrt()      # (p1,1)\n",
    "    ss2 = g2.sqrt()      # (p2,1)\n",
    "    p1, n = B.shape\n",
    "    p2, _ = A.shape\n",
    "    Z1 = torch.randn(p1, n); Z2 = torch.randn(p2, n)\n",
    "    Z1 /= Z1.norm(); Z2 /= Z2.norm() \n",
    "    for _ in range(it): \n",
    "        Y  = st * A_op(ss1 * Z1, ss2 * Z2, A, B)   # R^{1/2} A G^{1/2} Z\n",
    "        U  = st * Y                    # R A G^{1/2} Z\n",
    "        G1, G2 = A_adj(U, A, B)        # A^* R A G^{1/2} Z\n",
    "        Z1, Z2 = ss1 * G1, ss2 * G2     # G^{1/2} A^* R A G^{1/2} Z\n",
    "        s = (Z1.norm()**2 + Z2.norm()**2).sqrt()\n",
    "        Z1 /= s; Z2 /= s\n",
    "    return (st * A_op(ss1*Z1, ss2*Z2, A, B)).norm().item()\n",
    "\n",
    "\n",
    "# --- slow, **correct** K build by explicit indexing (column-major y, mixed z) ---\n",
    "def build_K_slow(A, B):\n",
    "    \"\"\"\n",
    "    y = vec_col(Y) with Y = Z1^T B + A^T Z2\n",
    "    z = [ vec_col(Z1^T) ; vec_col(Z2) ] = [ Z1.reshape(-1) ; Z2.T.reshape(-1) ]\n",
    "    K shape: (n^2) x (n*p1 + n*p2)\n",
    "    \"\"\"\n",
    "    p1, n = B.shape\n",
    "    p2, _ = A.shape\n",
    "    K = torch.zeros(n*n, n*(p1+p2), dtype=A.dtype, device=A.device)\n",
    "\n",
    "    # helper: row index for y(i,k) in vec_col(Y) = i + k*n\n",
    "    def ridx(i,k): return i + k*n\n",
    "\n",
    "    # left block: Z1 part (coeffs B[j,k] for var Z1[j,i])\n",
    "    # z1 index: vec_col(Z1^T) == row-major(Z1): idx1 = j*n + i\n",
    "    for i in range(n):       # row in Y\n",
    "        for k in range(n):   # col in Y\n",
    "            r = ridx(i,k)\n",
    "            for j in range(p1):\n",
    "                c = j*n + i\n",
    "                K[r, c] = B[j, k]\n",
    "\n",
    "    # right block: Z2 part (coeffs A[j,i] for var Z2[j,k])\n",
    "    # z2 index: vec_col(Z2) == column-major: idx2 = k*p2 + j\n",
    "    base = n*p1\n",
    "    for i in range(n):\n",
    "        for k in range(n):\n",
    "            r = ridx(i,k)\n",
    "            for j in range(p2):\n",
    "                c = base + k*p2 + j\n",
    "                K[r, c] = A[j, i]\n",
    "\n",
    "    return K\n",
    "\n",
    "\n",
    "\n",
    "# --- full test on small sizes (slow but reliable) ---\n",
    "def test_scaling_with_explicit_K(num_cases=30, eta=0.99, seed=0, verbose=True):\n",
    "    torch.manual_seed(seed)\n",
    "    fails = 0\n",
    "    for t in range(num_cases):\n",
    "        n  = torch.randint(3, 10, ()).item()    # keep small (explicit K is O(n^3))\n",
    "        p1 = torch.randint(2, 10, ()).item()\n",
    "        p2 = torch.randint(2, 10, ()).item()\n",
    "        A = torch.randn(p2, n)\n",
    "        B = torch.randn(p1, n)\n",
    "\n",
    "        # scaling\n",
    "        Rm, g1, g2 = pdhg_diagonal_scaling(A, B, eta=eta, debug=True)\n",
    "\n",
    "        # explicit K, R, G\n",
    "        K = build_K_slow(A, B)                        # (n^2, n(p1+p2))\n",
    "        I_n = torch.eye(n, dtype=A.dtype, device=A.device)\n",
    "        K2 = torch.cat([torch.kron(B.T.contiguous(), I_n), torch.kron(I_n, A.T.contiguous())], dim=1)\n",
    "        assert torch.allclose(K, K2), \"K build mismatch!\"\n",
    "\n",
    "        R_diag = Rm.T.reshape(-1)                     # vec_col(R) \n",
    "        R_half = torch.diag(torch.sqrt(R_diag))\n",
    "\n",
    "        # G diag for z = [ vec_col(Z1^T) ; vec_col(Z2) ]\n",
    "        # G1 = diag(s1) x I_n  (Z1 row j repeated across n columns)\n",
    "        # G2 = I_n x diag(s2)  (Z2 column-major)\n",
    "        s1 = g1.squeeze(-1); s2 = g2.squeeze(-1) \n",
    "        G_half = torch.block_diag(torch.kron(torch.diag(torch.sqrt(s1)), torch.eye(n)),\n",
    "                                  torch.kron(torch.eye(n), torch.diag(torch.sqrt(s2))))\n",
    "\n",
    "        # operator wiring check vs direct computation\n",
    "        Z1 = torch.randn(p1, n); Z2 = torch.randn(p2, n)\n",
    "        Y  = Z1.T @ B + A.T @ Z2\n",
    "        y  = Y.T.reshape(-1)                            # vec_col(Y)\n",
    "        z  = torch.cat([Z1.reshape(-1), Z2.T.reshape(-1)])\n",
    "        K_err = (y - K @ z).abs().max().item()\n",
    "\n",
    "        # bounds and spectral norm \n",
    "        smax = torch.linalg.svdvals(R_half @ K @ G_half)[0].item()\n",
    "\n",
    "        # implicit (should match SVD)\n",
    "        smax_impl = spec_norm_implicit(A, B, Rm, g1, g2, it=5000)\n",
    "\n",
    "        ok = (K_err <= 1e-6 + 1e-8 * torch.linalg.vector_norm(y).item()) and \\\n",
    "            (abs(smax - smax_impl) <= 1e-7 + 1e-6 * max(1.0, smax, smax_impl)) and \\\n",
    "                (smax <= eta*(1+1e-8))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{t:02d}] n={n} p1={p1} p2={p2}  \"\n",
    "                  f\"K_err={K_err:.2e}  \"\n",
    "                  f\"||R^1/2 K G^1/2||_2={smax:.6f}  (impl={smax_impl:.6f})  -> {'OK' if ok else 'FAIL'}\")\n",
    "        fails += 0 if ok else 1\n",
    "    print(f\"\\nSummary: {num_cases - fails} / {num_cases} passed (eta={eta}).\")\n",
    "    return fails\n",
    "\n",
    "# run\n",
    "_ = test_scaling_with_explicit_K(num_cases=20, eta=0.99, seed=1234, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae7f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "996d5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxpy_proj_subgrad_l1(AZ_np, Y_np):\n",
    "    m, n = AZ_np.shape\n",
    "    S = cp.Variable((m, n))\n",
    "    obj = cp.sum_squares(S - AZ_np)\n",
    "    constraints = []\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if Y_np[i, j] > 0:\n",
    "                constraints.append(S[i, j] == 1)\n",
    "            elif Y_np[i, j] < 0:\n",
    "                constraints.append(S[i, j] == -1)\n",
    "            else:\n",
    "                constraints.append(S[i, j] <= 1)\n",
    "                constraints.append(S[i, j] >= -1)\n",
    "    objective = cp.Minimize(obj)\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.CLARABEL, max_iter=10000, tol_gap_abs=1e-12, tol_gap_rel=1e-12)\n",
    "    assert prob.status in [\"optimal\"], print(prob.status)\n",
    "    return obj.value ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82976b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    Y = torch.randn(50, 50)\n",
    "    AZ = torch.randn(50, 50)\n",
    "    Y[Y.abs() < 0.1] = 0.0\n",
    "    val1, val1_rel = proj_subgrad_l1(AZ, Y)\n",
    "    val2 = cvxpy_proj_subgrad_l1(AZ.cpu().numpy(), Y.cpu().numpy())\n",
    "    assert np.allclose(val1, val2, rtol=1e-4, atol=1e-4), print(val1, val2)\n",
    "print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01d6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feba055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
