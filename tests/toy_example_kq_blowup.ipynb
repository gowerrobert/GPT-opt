{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa58fa2e",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9097ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n",
    "import einx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b93949",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "sequence =  100\n",
    "d_in = 64\n",
    "d_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f2c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.randn(batch, sequence, d_in)\n",
    "A = torch.randn(d_out, d_in)\n",
    "\n",
    "## Basic implementation\n",
    "Y1 = D @ A.T\n",
    "# Hard to tell the input and output shapes and what they mean.\n",
    "# What shapes can D and A have, and do any of these have unexpected behavior?\n",
    "\n",
    "## Einsum is self-documenting and robust\n",
    "# D A -> Y\n",
    "Y2 = einsum(D, A, \"batch sequence d_in, d_out d_in -> batch sequence d_out\")\n",
    "## Or, a batched version where D can have any leading dimensions but A is constrained.\n",
    "Y3 = einsum(D, A, \"... d_in, d_out d_in -> ... d_out\")\n",
    "\n",
    "assert torch.allclose(Y1, Y2) and torch.allclose(Y1, Y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e877e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)\n",
    "## Reshape and multiply\n",
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")\n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")\n",
    "dimmed_images1 = images_rearr * dim_value\n",
    "## Or in one go:\n",
    "dimmed_images2 = einsum(\n",
    "images, dim_by,\n",
    "\"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
    ")\n",
    "assert torch.allclose(dimmed_images1, dimmed_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have a batch of images represented as a tensor of shape (batch, height, width,\n",
    "# channel), and we want to perform a linear transformation across all pixels of the image, but this\n",
    "# transformation should happen independently for each channel. Our linear transformation is\n",
    "# represented as a matrix B of shape (height × width, height × width).\n",
    "channels_last = torch.randn(64, 32, 32, 3) # (batch, height, width, channel)\n",
    "B = torch.randn(32*32, 32*32)\n",
    "## Rearrange an image tensor for mixing across all pixels\n",
    "channels_last_flat = channels_last.view(\n",
    "-1, channels_last.size(1) * channels_last.size(2), channels_last.size(3)\n",
    ")\n",
    "channels_first_flat = channels_last_flat.transpose(1, 2)\n",
    "channels_first_flat_transformed = channels_first_flat @ B.T\n",
    "channels_last_flat_transformed = channels_first_flat_transformed.transpose(1, 2)\n",
    "channels_last_transformed = channels_last_flat_transformed.view(*channels_last.shape)\n",
    "# Instead, using einops:\n",
    "height = width = 32\n",
    "## Rearrange replaces clunky torch view + transpose\n",
    "channels_first = rearrange(\n",
    "channels_last,\n",
    "\"batch height width channel -> batch channel (height width)\"\n",
    ")\n",
    "channels_first_transformed = einsum(\n",
    "channels_first, B,\n",
    "\"batch channel pixel_in, pixel_out pixel_in -> batch channel pixel_out\"\n",
    ")\n",
    "channels_last_transformed = rearrange(\n",
    "channels_first_transformed,\n",
    "\"batch channel (height width) -> batch height width channel\",\n",
    "height=height, width=width\n",
    ")\n",
    "# Or, if you’re feeling crazy: all in one go using einx.dot (einx equivalent of einops.einsum)\n",
    "height = width = 32\n",
    "channels_last_transformed = einx.dot(\n",
    "\"batch row_in col_in channel, (row_out col_out) (row_in col_in)\"\n",
    "\"-> batch row_out col_out channel\",\n",
    "channels_last, B,\n",
    "col_in=width, col_out=width\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
